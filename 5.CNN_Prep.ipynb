{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image Generation from Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import read_file, transform_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Path('../data/audio')\n",
    "\n",
    "## Audio Directory\n",
    "NSynth_Audio = Data\n",
    "Train_Audio_Path = NSynth_Audio/'train'\n",
    "Valid_Audio_Path = NSynth_Audio/'valid'\n",
    "Test_Audio_Path = NSynth_Audio/'test'\n",
    "\n",
    "\n",
    "## Destination Path\n",
    "NSynth_Images = Data/'nsynth_images'\n",
    "Train_Image_Path = NSynth_Images/'train'\n",
    "Valid_Image_Path = NSynth_Images/'valid'\n",
    "Test_Image_Path = NSynth_Images/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length: 1000 \n",
      "Valid Length: 200 \n",
      "Test Length: 200\n"
     ]
    }
   ],
   "source": [
    "train_fnames = [f.name for f in Train_Audio_Path.iterdir()]\n",
    "valid_fnames = [f.name for f in Valid_Audio_Path.iterdir()]\n",
    "test_fnames = [f.name for f in Test_Audio_Path.iterdir()]\n",
    "\n",
    "print(\"Train Length:\", len(train_fnames), \"\\nValid Length:\", len(valid_fnames), \"\\nTest Length:\", len(test_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spec_tfm(fname, src_path, dst_path):\n",
    "    x, sample_rate = read_file(fname, src_path)\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 256\n",
    "    n_mels = 40\n",
    "    fmin = 20\n",
    "    fmax = sample_rate / 2 \n",
    "    \n",
    "    mel_spec_power = librosa.feature.melspectrogram(x, sr=sample_rate, n_fft=n_fft, \n",
    "                                                    hop_length=hop_length, \n",
    "                                                    n_mels=n_mels, power=2.0, \n",
    "                                                    fmin=fmin, fmax=fmax)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec_power, ref=np.max)\n",
    "    dst_fname = dst_path / (fname[:-4] + '.png')\n",
    "    plt.imsave(dst_fname, mel_spec_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Function Adapted from https://towardsdatascience.com/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc37b35ed4dd4b8f9ba0f88d66217bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c8685e0712401bb05ec85857b54e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5500424a46a4f08a88d2f5fa2f2c3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "transform_path(Train_Audio_Path, Train_Image_Path, log_mel_spec_tfm, \n",
    "               fnames=train_fnames, delete=True)\n",
    "\n",
    "## Valid\n",
    "transform_path(Valid_Audio_Path, Valid_Image_Path, log_mel_spec_tfm, \n",
    "               fnames=valid_fnames, delete=True)\n",
    "## Test\n",
    "transform_path(Test_Audio_Path, Test_Image_Path, log_mel_spec_tfm, \n",
    "               fnames=test_fnames, delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
